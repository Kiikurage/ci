# 2014-夏

## 1

### (1)

$$
\begin{align}
w_i^{(t)}
&= \prod_{j=1}^{t} P_i^{(j)}(x_j) \\
&= P_i^{(t)}(x_t) \cdot \prod_{j=1}^{t-1} P_i^{(j)}(x_j) \\
\therefore w_i^{(t)}
&= P_i^{(t)}(x_t) \cdot w_i^{(t-1)}
\end{align}
$$

$$　\sum_{i=1}^N v_i^{(t)} = 1　$$ より、

$$
\begin{align}
v_i^{(t+1)} 
&= \sum_{i=1}^N v_i^{(t+1)} \cdot \frac{w_i^{(t)}}{\sum_{i=1}^N w_i^{(t)}} \\
&= \frac{P_i^{(t)}(x_t) \cdot w_i^{(t-1)}}{\sum_{i=1}^N P_i^{(t)}(x_t) \cdot w_i^{(t-1)}}
\end{align}
$$

### (2)

$$ w^{(t-1)} $$と$$ v^{(t)} $$の比が等しいことから、(1)の式は次のように書き直せる

$$
\begin{align}
v_i^{(t+1)} 
&= \frac{P_i^{(t)}(x_t) \cdot w_i^{(t-1)}}{\sum_{i=1}^N P_i^{(t)}(x_t) \cdot w_i^{(t-1)}} \\
&= \frac{P_i^{(t)}(x_t) \cdot v_i^{(t)}}{\sum_{i=1}^N P_i^{(t)}(x_t) \cdot v_i^{(t)}} \\
&= \frac{P_i^{(t)}(x_t)}{\hat{P}^{(t)}(x_t)} v_i^{(t)}
\end{align}
$$

よって、擬似コードで表すと次のようになる。

```
// P: シニア予報士の予測
// p: 予報士の予測配列
//
// 予測は長さ2の配列で、1つめの要素が x=0 の確率を、
// 2つめの要素が x=1 の確率を表す

//重みの初期化
for i = 1~N {
  v[i] = 1/N
}

for t = 0~(T-1) {
  p = (各予報士の予測)

  //各予報士の予測結果に重みをつけて足す
  P[0] = 0;
  for i = 1~N {
    P[0] += p[i][0]*v;
  }
  P[1] = 1 - P[0]

  //シニア予報士の予測の出力
  output(P)
  
  //シニア予報士による予測が完了したので、
  //実際の天気が手に入る
  x = (実際の天気)

  //重みの更新
  for i = 1~N {
    v *= p[i][x] / P[x]
  }
}
```

計算量は、時間計算量が$$ O(NT) $$、空間計算量は$$ O(N) $$となる。ただし、各予報士の予測は瞬時に得られ、記憶領域を消費しないものとした。

### (3)

$$
\begin{align}
v_i^{(t+1)} 
&= \frac{P_i^{(t)}(x_t)}{\hat{P}^{(t)}(x_t)} v_i^{(t)} \\
&= \frac{P_i^{(t)}(x_t)}{\hat{P}^{(t)}(x_t)} \frac{P_i^{(t-1)}(x_{t-1})}{\hat{P}^{(t-1)}(x_t)} v_i^{(t-1)} \\
& \cdots \\
&= \frac{1}{N} \prod_{j=1}^{t} \frac{P_i^{(j)}(x_j)}{\hat{P}^{(j)}(x_j)}
\end{align}
$$

$$
\begin{align}
\therefore \hat{P}^{(t)} (x_t)
&= \sum_{i=1}^N v_i^{(t)} \cdot P_i^{(t)} (x_t) \\
&= \sum_{i=1}^N \biggl\{ \frac{1}{N} P_i^{(t)} (x_t) \prod_{j=1}^{t-1} \frac{P_i^{(j)}(x_j)}{\hat{P}^{(j)}(x_j)} \biggr\} \\
&= \frac{1}{N} \frac{1}{\prod_{j=1}^{t-1} \hat{P}^{(j)}(x_j)} \sum_{i=1}^N \prod_{j=1}^{t} P_i^{(j)}(x_j) \\
\end{align}
$$

$$
\begin{align}
\therefore - \log{ \hat{P}^{(T)} (x_T) }
&= \log{N} + \sum_{j=1}^{T-1} \log{ \hat{P}^{(j)}(x_j) } - \log{ \sum_{i=1}^N \prod_{j=1}^{T} P_i^{(j)}(x_j) } \\
&= \log{N} - Loss(x^{T-1}) - \log{ \sum_{i=1}^N \prod_{j=1}^{T} P_i^{(j)}(x_j) } \\
\therefore Loss(x^{T-1}) - \log{ \hat{P}^{(T)} (x_T) } &= \log{N} - \log{ \sum_{i=1}^N \prod_{j=1}^{T} P_i^{(j)}(x_j) } \\
\therefore Loss(x^{T}) &= \log{N} - \log{ \sum_{i=1}^N   \prod_{j=1}^{T} P_i^{(j)}(x_j) } \\
\end{align}
$$

### (4)
各予報士のT日間の累積予測損失は、i=1の予報士が最小であるとして一般性を失わない。

$$
\sum_{t=1}^{T} \biggl( -\log P_1^{(t)} (x_t) \biggr)
\leq \sum_{t=1}^{T} \biggl( -\log P_i^{(t)} (x_t) \biggr)
$$

(3)の結果より、$$ i = 1, \dots, N$$について、

$$
\begin{align}
Loss(x^{T}) &- \sum_{t=1}^{T} \biggl( -\log P_i^{(t)} (x_t) \biggr) \\
&= \log{N} - \log{ \sum_{i=1}^N \prod_{j=1}^{T} P_i^{(j)}(x_j) } - \sum_{t=1}^{T} \biggl( -\log P_i^{(t)} (x_t) \biggr) \\
&\leq \log{N}
\end{align}
$$

$$
\begin{align}
\therefore -\log{ \sum_{i=1}^N \prod_{j=1}^{T} P_i^{(j)}(x_j) }
&\leq \sum_{t=1}^{T} \biggl( -\log P_i^{(t)} (x_t) \biggr) \
\end{align}
$$

が成立すれば良い。

$$
\begin{align}
-\log{ \biggl( \sum_{i=1}^N \prod_{j=1}^{T} P_i^{(j)}(x_j) \biggr) }
&\leq -\log{ \biggl( \prod_{j=1}^{T} P_1^{(j)}(x_j) \biggr)} \\
&= \sum_{j=1}^{T} -\log{ \biggl(  P_1^{(j)}(x_j) \biggr)} \\
\end{align}
$$

よって、題意は示された。

##2

### (1)

不明（主記憶のサイズがわからなければ解けないのでは？近似？）

### (2)

LRUでは、主記憶に収まるサイズのデータに、プログラム全体を通じてアクセスし続ける場合、ページフォールトが起こりにくく高速化が期待できる。逆に、主記憶に収まらないサイズのデータ、例えば非常に大きな配列を全走査するようなアクセスの場合、必ずページフォールトが発生するため、実行速度が低下すると考えられる。よって、ループを展開するなどし、長い配列に対する全走査の回数をなるべく減らす処理が有効である。

### (3)

全てのページに対し、定期的にスワップ対象フラグを立てる。メモリアクセス時に、スワップ対象フラグが立っていればフラグを消す。ページフォールトが発生した際は、スワップ対象フラグが立っているページの内ランダムに1つをスワップ対象とする。これにより、一定時間内で一度もアクセスされなかった（最も遠い過去にアクセスされたとは限らないが、十分遠い過去にアクセスされた）ページを削除することが可能となる。

##3

### (1)

$$
\begin{align}
& (200 + 30 + 200 + 200) \cdot 0 \\
&+ (80 + 250 + 80 + 250) \cdot 1 \\
&+ 150 \cdot (-4) \\
&= 60
\end{align}
$$

### (2)

- (A) 画素値の合計
- (B) 重心
- Y1) $$ M00 = 12 $$、$$ M10 = 25 $$
- Y2) $$ M00 = 11 $$、$$ M10 = 28 $$

### (3)

k=1のときは、I4が選択されるため、 **I** であると識別される。
一方、k=3のときは、I4、C3、 C4が選択されるため、 **C** であると識別される。

### (4)

$$ CX_n $$ を、「カテゴリCの、n番目のサンプルのx座標」と定義する。同様に$$ CY_n, IX_n, IY_n $$を定義する。

識別境界上の点$$ (x, y) $$は次の関係を満たす

$$
\begin{align}
\sum_{i=1}^{4} \bigl[ (CX_i - x)^2+(CY_i - y)^2 \bigr]
- \sum_{i=1}^{4} \bigl[ (IX_i - x)^2+(IY_i - y)^2 \bigr] 
&= 0\\
\sum_{i=1}^{4} \bigl[ (CX_i - x)^2-(IX_i - x)^2 + (CY_i - y)^2 - (IY_i - y)^2 \bigr]
&= 0 \\
\end{align}
$$

$$
\begin{align}
\sum_{i=1}^{4} \bigl[CX_i^2 - IX_i^2 - 2x(CX_i - IX_i) + CY^2 - IY_i^2 - 2y(CY_i - IY_i) \bigr] = 0
\end{align}
$$

$$
\begin{align}
584 - 408 - 2x(48 - 40) + 2504 - 2918 - 2y(100 - 108) &= 0 \\
y - x - 14.875 &= 0 
\end{align}
$$

よって、$$ y - x - 14.875 \gt 0 $$のとき、カテゴリCからの距離が遠いためカテゴリIに識別され、逆に$$ y - x - 14.875 \lt 0$$のとき、カテゴリCに近いため、カテゴリCに識別される。

たとえば、$$ (13, 27) $$の場合、$$ 27 - 13 - 14.875 = -0.875 \lt 0 $$より、 **カテゴリC** に識別される。

### (5)

??????

## 4

### (1)tf-idf

文章中に含まれる単語に対する指標の一種。単語の出現頻度(Term-Frequency, tf)と、単語を含む文章の出現頻度の逆数（Inverse-Document-Frequncy, idf）を用いて、

$$ (tf-idf) = tf \cdot idf $$

と計算される。tfが高い単語は、それだけ出現頻度が高く重要な単語であるといえるが、どの文章にも頻繁に出現する単語は「単語を含む文章の出現頻度（Document-Frequency）」が高く、idfが低くなるため、結果的にtf-idfは低くなる。よって、文章中の特徴的な単語を抽出することができる指標と言え、文章要約や、スパムメールのフィルタリングなどに用いられる。

### (2)ZMP

メカトロニクスはムリ！

### (3)分散ハッシュ

ネットワーク上の複数のピアでハッシュテーブルを分散管理する技術である。これにより、一部のピアへ負荷が集中することを避ける事が可能となる。各ピアはハッシュテーブルの一部及びルーティング情報を管理しており、普通、どのピアからも任意のキーへO(n)未満でのアクセスが可能になるようルーティング方法が工夫されている。P2P技術と比較すると、P2P技術は「元データを複数のピアがコピーして保持し、リクエストはネットワーク上に無作為に発信され、対応するデータを持っているピアがこれに応答する」というアーキテクチャであるのに対し、分散ハッシュでは「データのコピーは作成せず、ルーティング情報に従って元データを持っているピアへ直接アクセスする」というアーキテクチャである。ノードの追加・脱退に応じてどのようにルーティング・データ分割を管理するかが重要となる。


### (4)最短経路問題

最短経路問題とは、重み付き有向グラフにおいて、与えられた2点を始点・終点とするパスの内、最も短いパスを探索するという最適化問題の一種である。解法として「ダイクストラ法」というアルゴリズムが知られている。このアルゴリズムの概要は次のようになる。

0. 始点から各頂点までの移動コストを考える。初期状態では全ての点への移動コストは無限大であるとする。
1. 始点から繋がる各点について、パスの重みを用いて移動コストを更新する。
2. 始点からの移動コストが最小な点(pとする)を選ぶ
3. pが終点であり、かつまだ選択していない点がすべて始点-終点間のコストより大きなコストがかかることが判明している場合、その時点で探索を終了する。
4. そうでなければ、pから繋がる全ての点(qとする)について、移動コストを更新する。具体的には、始点からpまでの移動コストに、pからqまでの移動コストを加えれば良い。ただし、これまでに計算された移動コストのほうが小さい（すなわち、始点から、pを通らずにqへ向かったほうがコストが小さい）場合は更新をしない。
5. 更新後、まだpとして選択していない点を選択し、3,4の操作を繰り返す。

ダイクストラ法は辺のコストがマイナスの場合は一般に適用できず改良が必要である。

### (5)ベイジアンネットワーク

ベイジアンネットワークとは複数の確率変数の因果関係を表現したネットワークモデルである。事象AとBの間に A -> B という因果関係がある場合、A,Bが起こる確率P(A,B)はベイズの定理を用いて P(A,B) = P(B|A)*P(A) と表現される。これをベイジアンネットワークでは

```
--> [ A ] ----> [ B ] -->
```

と表現する。Bの出力は、入力であるAの出力に依存している。このモデルを用いることで、ある確率変数の値が入力された際に、他の説明変数の確率分布を求めることが可能である。要因解析や予測などに広く活用される。


### (6)キャリールックアヘッド

複数bitの加算器では、下位bitで発生した繰り上がり信号（キャリー信号）を正しく処理する必要がある。よって、1bitの加算器を直列につなげた加算器では、下位bitの計算を待ってから上位bitの計算を行う必要があり、これは回路の遅延の原因となる。そこで、各加算器への入力から、予めキャリー信号を計算しておくことで、各1bit加算器を並列に並べた構造を取ることが可能となる。このようにキャリー信号を先読みする構造をキャリールックアヘッドと呼ぶ。

### (7)クロージャ

プログラミング言語において、関数内の変数の参照解決がその関数の実行時のスコープではなく宣言されたスコープで行われるような関数オブジェクトをクロージャという。以下のjavascriptのコードは、クロージャを用いてカウンタを実装した例である。

```javascript
function makeCounter(){
  var x = 0;
  var closure = function(){
    x++;
    return x;
  };
  
  return closure
}

var count = makeCounter();

count(); //-> 1
count(); //-> 2
count(); //-> 3
```

この例において、プログラム後半、count() を実行しているグローバルスコープからは、makeCounter内で宣言される変数xを参照することはできない。しかし、count関数（正確には、変数countに代入された関数オブジェクト）は宣言されたmakeCounter() のスコープで変数の参照が解決される。そのため変数xを参照することができ、カウントが行えるのである。このとき、countに代入された関数オブジェクトをクロージャと呼ぶ。

### (8)有限オートマトン

有限個の状態をもつオートマトンを有限オートマトンという。様々な問題の基本的なモデルとして応用される。例えば、構文解析の分野においては、文章を予めトークンとして分割し、このトークン列を入力として構文解析を行う。オートマトンの各状態は、文法（構文木）が現在どのように解釈され、次にどのような入力が来るべきか、を表す。トークン列が全て入力された後に、受理状態に到達しない、または入力途中で遷移不可能な入力がなされた場合には、入力された文章が文法上の間違いを含んでいることを表す。例として、符号付きの数値（整数・小数どちらも含み、西条桁に0がきたり、小数点の後ろに数字が続かないなどの例外を含む）のみを受容するオートマトンを示す。

```
オートマトンを書くのはムリなので、分解して表現してます

 [ FIRST ]  --- + - --->  [  SIGN ]
 [ FIRST ]  ---  0  ---> [[  ZERO ]]
 [ FIRST ]  --- 1~9 ---> [[  INT  ]]

 [  SIGN ]  ---  0  ---> [[  ZERO ]]
 [  SIGN ]  --- 1~9 ---> [[  INT  ]]

[[  INT  ]] --- 0~9 ---> [[  INT  ]]
[[  INT  ]] ---  .  --->  [ POINT ]

[[  ZERO ]] ---  .  --->  [ POINT ]

 [ POINT ]  --- 0~9 ---> [[ FLOAT ]]

[[ FLOAT ]] --- 0~9 ---> [[ FLOAT ]]
```
